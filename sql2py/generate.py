import argparse
import os
import sys
from typing import List, Tuple, Union, TypedDict, Literal, Optional
from parsers.PostgresqlLexer import PostgresqlLexer
from parsers.PostgresqlParser import PostgresqlParser
from antlr4 import CommonTokenStream
from antlr4.InputStream import InputStream
import psycopg2


from sql2py.parse_sqlite import parse_query_types, parse_schema
from sql2py.parse_sqlite import get_db_schema_text


class Sql2pyError(Exception):
    pass


def to_snake_case(description: str) -> str:
    if description.strip()[0].isnumeric():
        raise Sql2pyError('Description should not contain leading numeric characters')
    words = description.split()
    words = [word.strip().lower() for word in words]
    words = [word for word in words if len(word) > 0 and word.isalnum()]
    name = '_'.join(words)
    name = ''.join(c for c in name if c.isalnum() or c == '_')
    return name


def generate_function(description: str,
                      sql_query: str,
                      schema_text: str,
                      is_async: bool = False) -> str:

    template = \
'''<<<TYPE_CLASS>>>
def <<<NAME>>>(<<<PARAMS>>>) -> <<<RETURN_TYPE>>>:
    \'\'\'
    <<<DESCRIPTION>>>
    ---
    SQL: <<<SQL_QUERY>>>
    \'\'\'

    cur = con.cursor()
    cur.execute('<<<SQL_QUERY>>>', <<<BINDINGS>>>)
    res: List[Any] = []
    output_names: List[str] = <<<OUTPUT_NAME_LIST>>>
    for row in cur.fetchall():
        row_dict = dict()
        for k, v in zip(output_names, row):
            row_dict[k] = v
        res.append(row_dict)
    <<<RETURN_STATEMENT>>>'''


    inputs, outputs = parse_query_types(sql_query, schema_text)
    name = to_snake_case(description)

    params = ', '.join(f'{c["name"]}: {c["type"]}' for c in inputs)

    if len(inputs) > 0:
        bindings = '(' + ', '.join(c["name"] for c in inputs) + ',)'
    else:
        bindings = ''
    output_name_list = '[' + ', '.join([f'\'{c["name"]}\'' for c in outputs]) + ']'

    if len(outputs) > 0:
        type_class = f'class ReturnType_{name}(TypedDict):\n'
        for c in outputs:
            type_class += '    ' + c['name'] + ': ' + c['type'] + '\n'
        return_type = f'List[ReturnType_{name}]'
        return_statement = f'return cast({return_type}, res)'
    else:
        type_class = ''
        return_type = 'None'
        return_statement = 'return None'

    template = template.replace('<<<NAME>>>', name)
    template = template.replace('<<<SQL_QUERY>>>', sql_query)
    template = template.replace('<<<PARAMS>>>', params)
    template = template.replace('<<<DESCRIPTION>>>', description)
    template = template.replace('<<<BINDINGS>>>', bindings)
    template = template.replace('<<<OUTPUT_NAME_LIST>>>', output_name_list)
    template = template.replace('<<<TYPE_CLASS>>>', type_class)
    template = template.replace('<<<RETURN_STATEMENT>>>', return_statement)
    template = template.replace('<<<RETURN_TYPE>>>', return_type)
    return template


class QueryInfo(TypedDict):
    desc: str
    sql: str

def read_query_file(filename: str) -> List[QueryInfo]:
    if not os.path.exists(filename):
        raise Sql2pyError(f'No such file \'{filename}\'.')

    with open(filename, 'r') as f:
        lines = list(f)

    pairs: List[QueryInfo] = []
    last_desc: Union[None, str] = None
    for idx, line in enumerate(lines):
        s = lines[idx].strip()
        if len(s) == 0:
            continue
        if s.startswith('--'):
            # description
            if last_desc is None:
                last_desc = s[2:].strip()
            else:
                raise Sql2pyError(f'Expected SQL statement on line {idx}.')
        else:
            # SQL statement
            if last_desc is not None:
                pairs.append({
                    'desc': last_desc,
                    'sql': s.strip()
                })
                last_desc = None
            else:
                raise Sql2pyError(f'Expected comment description on line {idx}.')

    return pairs


def generate_old(input_filename: str,
             output_filename: str,
             db_filename: str) -> None:

    template = \
'''# This file has been generated by sql2py. DO NOT EDIT MANUALLY!

import sqlite3
from typing import cast, List, TypedDict, Any

con = sqlite3.connect(\'<<<DB_FILENAME>>>\')


<<<FUNCTIONS>>>
'''

    schema_text = get_db_schema_text(db_filename=db_filename)
    queries = read_query_file(input_filename)
    functions = []
    for query in queries:
        function = generate_function(description=query['desc'],
                                     sql_query=query['sql'],
                                     schema_text=schema_text,
                                     is_async=False)
        functions.append(function)

    template = template.replace('<<<DB_FILENAME>>>', db_filename)
    template = template.replace('<<<FUNCTIONS>>>', '\n\n'.join(functions))

    with open(output_filename, 'w') as f:
        f.write(template)



class Field(TypedDict):
    name: str
    data_type: str
    is_nullable: bool

class Statement(TypedDict):
    ttype: Literal['CREATE', 'DROP', 'SELECT', 'INSERT', 'DELETE']
    inputs: List[Field]
    outputs: List[Field]
    table_name: Optional[str]
    original: str

class Column(TypedDict):
    name: str
    data_type: str
    is_nullable: bool

class Table(TypedDict):
    name: str
    columns: List[Column]


def get_schema(dbname: str, user: str, password: str) -> List[Table]:
    con = psycopg2.connect(f'dbname={dbname} user={user} password={password}')
    cur = con.cursor()
    cur.execute('''
        SELECT
            table_name,
            column_name,
            data_type,
            is_nullable,
            column_default
        FROM information_schema.columns
        WHERE table_schema not in ('information_schema', 'pg_catalog');
    ''')
    rows = cur.fetchall()
    uniq = set()
    for table_name, column_name, data_type, is_nullable, column_default in rows:
        uniq.add(table_name)
    tables: List[Table] = []
    for table_name in uniq:
        columns: List[Column] = []
        for _table_name, column_name, data_type, is_nullable, column_default in rows:
            if table_name == _table_name:
                columns.append(Column(
                    name=column_name,
                    data_type=data_type,
                    is_nullable=is_nullable == 'YES',
                ))
        tables.append(Table(
            name=table_name,
            columns=columns
        ))
    return tables


def find_table(tables: List[Table], name: str) -> Optional[Table]:
    for table in tables:
        if table['name'] == name:
            return table
    return None


def find_field(fields: List[Field], name: str) -> Optional[Field]:
    for field in fields:
        if field['name'] == name:
            return field
    return None


def generate(queries: str, dbname: str, user: str, password: str) -> str:
    schema = get_schema(dbname=dbname, user=user, password=password)
    input_stream = InputStream(queries)
    lexer = PostgresqlLexer(input_stream)
    token_stream = CommonTokenStream(lexer)
    parser = PostgresqlParser(token_stream)
    query_list = parser.queries()
    # print(query_list.toStringTree(parser.ruleNames))
    statements: List[Statement] = []
    for query in query_list.query():
        create_query = query.create_query()
        drop_query = query.drop_query()
        select_query = query.select_query()
        insert_query = query.insert_query()
        delete_query = query.delete_query()
        empty_query = query.empty_query()

        if create_query:
            i = create_query.getSourceInterval()
            original = queries[i[0]:i[1]]
            table_ref = create_query.table_ref()
            table_name = table_ref.ID().getText()
            column_defs = create_query.column_defs()
            outputs: List[Field] = []
            for column_def in column_defs.column_def():
                column_type = column_def.column_type()
                tokens = [c.getText() for c in column_type.getChildren()]
                not_null = len(tokens) == 3 and tokens[1].lower() == 'not' and tokens[2].lower() == 'null'
                outputs.append(
                    Field(
                        name=column_def.ID().getText(),
                        data_type=tokens[0],
                        is_nullable=not not_null,
                    )
                )
            statements.append(Statement(
                ttype='CREATE',
                inputs=[],
                outputs=outputs,
                table_name=table_name,
                original=original
            ))

        elif drop_query:
            i = drop_query.getSourceInterval()
            original = queries[i[0]:i[1]]
            statements.append(Statement(
                ttype='DROP',
                inputs=[],
                outputs=[],
                table_name=drop_query.ID().getText(),
                original=original,
            ))

        elif select_query:
            i = select_query.getSourceInterval()
            original = queries[i[0]:i[1]]
            column_refs = select_query.column_refs()
            column_ref = column_refs.column_ref()
            table_ref = select_query.table_ref()
            table_name = table_ref.ID().getText()
            table = find_table(schema, table_name)
            if table is None:
                raise ValueError(f'No such table {table_name}')
            outputs: List[Field] = []
            if column_ref:
                for ref in column_ref:
                    column_name = ref.ID().getText()
                    field = find_field(table['columns'], column_name)
                    if field is None:
                        raise ValueError(f'Table {table_name} does not have column named {column_name}')
                    outputs.append(field)
            else:
                children = [c.getText() for c in column_refs.getChildren()]
                assert len(children) == 1
                assert children[0] == '*'
                outputs += table['columns']
            inputs: List[Field] = []  # TODO
            statements.append(Statement(
                ttype='SELECT',
                inputs=inputs,
                outputs=outputs,
                table_name=table_name,
                original=original
            ))

        elif insert_query:
            table_ref = insert_query.table_ref()
            table_name = table_ref.ID().getText()

        elif delete_query:
            pass

        elif empty_query:
            pass

        else:
            raise ValueError('Invalid query type')

    for s in statements:
        print(' -> ', s)

    return 'asd'


def main():
    parser = argparse.ArgumentParser(description='Convert SQLite queries to Python functions.')
    parser.add_argument('-i', '--input',
                        type=str,
                        help='the input SQL file to parse',
                        default='queries.sql')
    parser.add_argument('-o', '--output',
                        type=str,
                        help='the output Python file to generate',
                        default='queries.py')
    parser.add_argument('-f', '--db-filename',
                        type=str,
                        help='the SQLite database filename',
                        required=True)
    args = parser.parse_args()
    with open(args.input, 'r') as f:
        sql = f.read()
    code = generate(sql, dbname=args.dbname, user=args.user, password=args.password)
    with open(args.output, 'w') as f:
        f.write(code)


if __name__ == '__main__':
    main()
